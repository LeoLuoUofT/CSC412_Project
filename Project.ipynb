{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG5MA9DB1vD6"
   },
   "source": [
    "# Gaussian Mixture VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_NvEAosY_Wg"
   },
   "source": [
    "Many utilities borrowed from https://github.com/jariasf/GMVAE/blob/master/pytorch/networks/Layers.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJlMOIXC135X"
   },
   "source": [
    "## Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "qMCUUPqdF9N4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "fYIrwlLKULu8"
   },
   "outputs": [],
   "source": [
    "def get_activation_function(id):\n",
    "  if id == 'relu':\n",
    "    return nn.ReLU()\n",
    "  \n",
    "  if id == 'sigmoid':\n",
    "    return nn.Sigmoid()\n",
    "\n",
    "  if id == 'tanh':\n",
    "    return nn.Tanh()\n",
    "\n",
    "  if id == 'none':\n",
    "    return nn.Identity()\n",
    "\n",
    "  else:\n",
    "    raise ValueError\n",
    "\n",
    "def get_batch_norm(bool, size):\n",
    "  if bool:\n",
    "    return nn.BatchNorm1d(size)\n",
    "\n",
    "  else:\n",
    "    return nn.Identity()\n",
    "\n",
    "def get_rnn_cell(id):\n",
    "  # returns constructor\n",
    "  if id == 'gru':\n",
    "    return nn.GRU\n",
    "\n",
    "  if id == 'lstm':\n",
    "    return nn.LSTM  \n",
    "\n",
    "  if id == 'basic':\n",
    "    return nn.RNN # why use this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "DISAE6n11tZa"
   },
   "outputs": [],
   "source": [
    "class ff(nn.Module):\n",
    "    def __init__(self, argdict):\n",
    "      \"\"\"\n",
    "      argdict: contains all arguments \n",
    "      \"\"\"\n",
    "      super(ff, self).__init__()\n",
    "\n",
    "      self.argdict = argdict\n",
    "\n",
    "      input_dim = self.argdict[\"input_dim\"]\n",
    "      output_dim = self.argdict[\"output_dim\"]\n",
    "      if \"layer_params\" in self.argdict:\n",
    "        layer_params = self.argdict[\"layer_params\"]\n",
    "        n_layers = len(layer_params)\n",
    "      else:\n",
    "        n_layers = 0  \n",
    "\n",
    "      \n",
    "      self.layers = []\n",
    "      \n",
    "      if n_layers != 0:\n",
    "        self.layers.append(\n",
    "          nn.Sequential(\n",
    "            nn.Linear(input_dim, layer_params[0][\"size\"]),\n",
    "            get_batch_norm(self.argdict[0][\"batch_norm\"], layer_params[0][\"size\"]),\n",
    "            get_activation_function(layer_params[0][\"activation_fn\"])\n",
    "          )\n",
    "        )\n",
    "      \n",
    "        for i in range(n_layers-1):\n",
    "          self.layers.append(\n",
    "            nn.Sequential(\n",
    "              nn.Linear(layer_params[i][\"size\"], layer_params[i+1][\"size\"]),\n",
    "              get_batch_norm(self.argdict[i+1][\"batch_norm\"], layer_params[i+1][\"size\"]),\n",
    "              get_activation_function(layer_params[i+1][\"activation_fn\"])\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.layers.append(\n",
    "            nn.Sequential(\n",
    "              nn.Linear(layer_params[-1][\"size\"], output_dim),\n",
    "              get_activation_function(self.argdict[\"output_activation_fn\"])\n",
    "            )\n",
    "        )\n",
    "\n",
    "      # 0 layer case, just pipe to output\n",
    "      else:\n",
    "        self.layers.append(\n",
    "            nn.Sequential(\n",
    "              nn.Linear(input_dim, output_dim),\n",
    "              get_activation_function(self.argdict[\"output_activation_fn\"])\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "      for layer in self.layers:\n",
    "        x = layer(x)\n",
    "\n",
    "      return x\n",
    "\n",
    "class rnn(nn.Module):\n",
    "    def __init__(self, argdict):\n",
    "      \"\"\"\n",
    "      \"\"\"\n",
    "      super(rnn, self).__init__()\n",
    "\n",
    "      self.argdict = argdict\n",
    "\n",
    "      # no embedding? assume already embedded\n",
    "\n",
    "      input_dim = self.argdict[\"input_dim\"]\n",
    "      output_dim = self.argdict[\"output_dim\"]\n",
    "        \n",
    "      # hidden default to zero\n",
    "\n",
    "      rnn_cell_constructor = get_rnn_cell(self.argdict[\"rnn_cell\"])\n",
    "\n",
    "      self.rnn_layer = rnn_cell_constructor(input_dim, output_dim, batch_first = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "      return self.rnn_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "PbCN9IjPChPA"
   },
   "outputs": [],
   "source": [
    "# sampling\n",
    "def gumbel_sampler(x, temperature):\n",
    "    # softmax but with noise\n",
    "    sampled = torch.rand(x.size())\n",
    "    eps = 1e-10 # stability\n",
    "    if x.is_cuda:\n",
    "      sampled = sampled.cuda()\n",
    "    noise = torch.log(-torch.log(sampled + eps) + eps) # loglog\n",
    "    return F.softmax((x - noise) / temperature, dim=-1)\n",
    "\n",
    "def gaussian_sampler(m, v):\n",
    "    std = torch.sqrt(v + 1e-10)\n",
    "    eps = torch.randn_like(std)\n",
    "    z = m + eps * std\n",
    "    return z\n",
    "\n",
    "# losses\n",
    "def cross_entropy(logits, labels):\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "def mse(pred, labels):\n",
    "    loss = (pred - labels).pow(2)\n",
    "    return loss.sum(-1).mean()\n",
    "\n",
    "def entropy(logits, labels):\n",
    "    # wrt logits\n",
    "    log_q = F.log_softmax(logits, dim=-1)\n",
    "    return -torch.mean(torch.sum(labels * log_q, dim=-1))\n",
    "\n",
    "def log_normal(z, m, v):\n",
    "    v_stable = v + 1e-10\n",
    "    return -0.5 * torch.sum(torch.pow(z - m, 2)/v + torch.log(v), dim=-1) # ignore constant \n",
    "\n",
    "def gaussian_kl(sample, mu, var, mu_prior, var_prior):\n",
    "    loss = log_normal(sample, mu, var) - log_normal(sample, mu_prior, var_prior)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "mlP_umuVKiEO"
   },
   "outputs": [],
   "source": [
    "class softmax_with_gumbel(nn.Module):\n",
    "\n",
    "  def __init__(self, argdict):\n",
    "    super(softmax_with_gumbel, self).__init__()\n",
    "    \n",
    "    self.argdict = argdict\n",
    "\n",
    "    input_dim = argdict[\"input_dim\"]\n",
    "    output_dim = argdict[\"output_dim\"]\n",
    "    self.layer = nn.Linear(input_dim, output_dim)\n",
    "    self.activation = nn.Softmax(dim = -1)\n",
    "  \n",
    "  def forward(self, x, temperature = 1.0):\n",
    "    x = self.layer(x)\n",
    "    y = gumbel_sampler(x, temperature)\n",
    "    return self.activation(x), y # logits, y\n",
    "\n",
    "class gaussian(nn.Module):\n",
    "  def __init__(self, argdict):\n",
    "    super(gaussian, self).__init__()\n",
    "\n",
    "    self.argdict = argdict\n",
    "    input_dim = argdict[\"input_dim\"]\n",
    "    output_dim = argdict[\"output_dim\"]\n",
    "\n",
    "    self.mu_layer = nn.Linear(input_dim, output_dim)\n",
    "    self.var_layer = nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Softplus() # need softplus\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    mu = self.mu_layer(x)\n",
    "    var = self.var_layer(x)\n",
    "    z = gaussian_sampler(mu, var)\n",
    "    return mu, var, z    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "nLuLzcyBGOnn"
   },
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "  def __init__(self, argdict):\n",
    "    super(encoder, self).__init__()\n",
    "\n",
    "    self.argdict = argdict\n",
    "    \n",
    "    # q(y|x)\n",
    "    self.q_y_rnn = torch.nn.Sequential(\n",
    "      rnn(argdict[\"q_y_rnn\"]), # rnn component                                    \n",
    "    ) # make sure to constrain arguments\n",
    "    \n",
    "    self.q_y_linear = ff(argdict[\"q_y_linear\"])\n",
    "    \n",
    "    self.q_y = softmax_with_gumbel(argdict[\"q_y_gumbel\"]) # separate for temperature parameter\n",
    "    \n",
    "    # q(z|y,x)\n",
    "    self.q_z_recurrent = rnn(argdict[\"q_z_rnn\"])\n",
    "    \n",
    "    self.q_z = torch.nn.Sequential( # rnn?? can remove if buggy\n",
    "      ff(argdict[\"q_z_linear\"]),\n",
    "      gaussian(argdict[\"q_z_gaussian\"])                                          \n",
    "    ) # make sure to constrain arguments\n",
    "  \n",
    "  def forward_fixed_y(self, x, y_fixed):\n",
    "    # for style transfer\n",
    "    x = self.q_z_recurrent(x)[0][:,-1,:]\n",
    "    \n",
    "    mu, var, z = self.q_z(torch.cat((x, y_fixed), dim=1))\n",
    "    return_dict = {'mu': mu, 'var': var, 'z': z}\n",
    "    return return_dict\n",
    "\n",
    "  def forward(self, x, temperature = 1.0):\n",
    "    pre_y = self.q_y_rnn(x)[0][:,-1,:]\n",
    "    pre_y = self.q_y_linear(pre_y)\n",
    "    pi, y = self.q_y(pre_y, temperature = temperature)\n",
    "    \n",
    "    x = self.q_z_recurrent(x)[0][:,-1,:]\n",
    "    mu, var, z = self.q_z(torch.cat((x, y), dim=1))\n",
    "    \n",
    "    return_dict = {'pi': pi, 'y': y, 'mu': mu, 'var': var, 'z': z}\n",
    "    return return_dict\n",
    "\n",
    "class decoder(nn.Module):\n",
    "  def __init__(self, argdict):\n",
    "    super(decoder, self).__init__()\n",
    "\n",
    "    self.argdict = argdict\n",
    "    input_dim = self.argdict[\"input_dim\"] # y_dim\n",
    "    output_dim = self.argdict[\"output_dim\"] # z_dim\n",
    "    # make sure dims match when constructing args\n",
    "\n",
    "    self.p_z_mu_nn = nn.Linear(input_dim, output_dim)\n",
    "    self.p_z_var_nn = nn.Sequential(\n",
    "      nn.Linear(input_dim, output_dim),\n",
    "      nn.Softplus()\n",
    "    )\n",
    "\n",
    "    self.p_x = torch.nn.Sequential(\n",
    "      ff(argdict[\"p_x_linear\"]),\n",
    "      rnn(argdict[\"p_x_rnn\"]),\n",
    "    ) # apply activations on output\n",
    "    \n",
    "    # technically the mean vector should not be a sequential, but this is too annoying to implement\n",
    "\n",
    "  def forward(self, z, y, seq_len):\n",
    "    z_mu = self.p_z_mu_nn(y)\n",
    "    z_var = self.p_z_var_nn(y)\n",
    "    \n",
    "    z = z.view(z.shape[0], 1, z.shape[1])\n",
    "    \n",
    "    z_seq = z.repeat(1, seq_len, 1) # tiling for sequence\n",
    "    \n",
    "    x = self.p_x(z_seq)[0]\n",
    "\n",
    "    return_dict = {'mu': z_mu, 'var': z_var, 'x': x}\n",
    "    return return_dict\n",
    "\n",
    "class GMVAE(nn.Module):\n",
    "  def __init__(self, argdict):\n",
    "    super(GMVAE, self).__init__()\n",
    "\n",
    "    self.encoder = encoder(argdict[\"encoder\"])\n",
    "    self.decoder = decoder(argdict[\"decoder\"])\n",
    "\n",
    "    # weight initialization\n",
    "    for m in self.modules():\n",
    "      if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "      #elif type(m) == nn.RNN or type(m) == nn.GRU or type(m) == nn.LSTM:\n",
    "      #  torch.nn.init.kaiming_normal_(m.weight) # RNN weighting\n",
    "      # don't do this, too complicated\n",
    "\n",
    "  def style_transfer(self, x, y_fixed):\n",
    "    # y_fixed should be binary vector with the target style\n",
    "\n",
    "    encoder_returns = self.encoder.forward_fixed_y(x, y_fixed)\n",
    "    z = encoder_returns['z']\n",
    "    decoder_returns = self.decoder(z, y_fixed)\n",
    "    \n",
    "    return_dict = {\"encoder\": encoder_returns, \"decoder\": decoder_returns}\n",
    "    return return_dict\n",
    "\n",
    "  def forward(self, x, temperature=1.0):\n",
    "    # standard\n",
    "\n",
    "    encoder_returns = self.encoder(x, temperature = temperature)\n",
    "    z, y = encoder_returns['z'], encoder_returns['y']\n",
    "    decoder_returns = self.decoder(z, y, x.shape[1])\n",
    "    \n",
    "    return_dict = {\"encoder\": encoder_returns, \"decoder\": decoder_returns}\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "hWQ0AndtiVeY"
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "  def __init__(self, argdict):\n",
    "    # unpacking 50000000 args\n",
    "    # lr control\n",
    "\n",
    "    # lr variable\n",
    "    self.init_learning_rate = argdict[\"learning_rate\"]\n",
    "    self.learning_rate = self.init_learning_rate\n",
    "\n",
    "    # decay parameters\n",
    "    self.decay_epoch = argdict[\"decay_epoch\"]\n",
    "    self.lr_decay = argdict[\"lr_decay\"]\n",
    "\n",
    "    # weighting for loss\n",
    "    self.weight_style = argdict[\"weight_style\"]\n",
    "    self.weight_entropy = argdict[\"weight_entropy\"]\n",
    "    self.weight_sampling = argdict[\"weight_sampling\"]\n",
    "\n",
    "    # mix different audio??   \n",
    "    self.weight_pitch = argdict[\"weight_pitch\"]\n",
    "\n",
    "    # self.weight_instrument = argdict[\"weight_instrument\"]\n",
    "    self.weight_velocity = argdict[\"weight_velocity\"]\n",
    "\n",
    "    # sizes, make sure it matches\n",
    "    self.pitch_size = argdict[\"pitch_size\"]\n",
    "    self.instrument_size = argdict[\"instrument_size\"]\n",
    "    self.velocity_size = argdict[\"velocity_size\"]\n",
    "\n",
    "    # temperature for sampling for GMM, very annoying\n",
    "    self.init_temp = argdict[\"init_temp\"]\n",
    "    self.decay_temp = argdict[\"decay_temp\"]\n",
    "    self.min_temp = argdict[\"min_temp\"]\n",
    "    self.decay_temp_rate = argdict[\"decay_temp_rate\"]\n",
    "\n",
    "    # temperature variable\n",
    "    self.gumbel_temp = self.init_temp\n",
    "\n",
    "    # epochs, etc\n",
    "    self.num_epochs = argdict[\"num_epochs\"]\n",
    "    self.save_epoch = argdict[\"save_epoch\"]\n",
    "    self.log_epoch = argdict[\"log_epoch\"]\n",
    "    \n",
    "    self.save_path = argdict[\"save_path\"]\n",
    "    \n",
    "    if not os.path.exists(self.save_path):\n",
    "        os.makedirs(self.save_path)\n",
    "\n",
    "    self.model = GMVAE(argdict)\n",
    "    if argdict[\"cuda\"]:\n",
    "      self.model = self.model.cuda()\n",
    "\n",
    "    self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "  def _elbo(self, pitch, instrument, velocity, style_label):\n",
    "    \n",
    "    x = torch.cat((pitch, instrument, velocity), dim=-1) # should be dim = 3\n",
    "    \n",
    "    return_dict = self.model(x, temperature = self.gumbel_temp)\n",
    "\n",
    "    x_pred = return_dict[\"decoder\"][\"x\"]\n",
    "    pitch_pred, instrument_pred, velocity_pred = \\\n",
    "      torch.split(x_pred, [self.pitch_size, self.instrument_size, self.velocity_size], dim=-1)\n",
    "\n",
    "    # renormalizing?\n",
    "    velocity_pred = (velocity_pred + 1)/2 # is this correct? output of RNN should be in [0, 1]\n",
    "\n",
    "    pitch_label = torch.argmax(pitch, dim=2).view(-1)\n",
    "    pitch_pred = torch.reshape(pitch_pred, (-1, self.pitch_size))\n",
    "    \n",
    "    loss_pitch = cross_entropy(pitch_pred, pitch_label)\n",
    "    # loss_instrument = cross_entropy(instrument_pred, torch.argmax(instrument, dim = -1))\n",
    "    loss_velocity = mse(velocity, velocity_pred)\n",
    "\n",
    "    style_logits = return_dict[\"encoder\"][\"pi\"]\n",
    "    y_pred = return_dict[\"encoder\"][\"y\"]\n",
    "\n",
    "    # style label may need copying\n",
    "    loss_style = cross_entropy(style_logits, style_label.long()) # style label is not 1-hot?\n",
    "    loss_entropy = entropy(style_logits, y_pred)\n",
    "\n",
    "    z_pred = return_dict[\"encoder\"][\"z\"]\n",
    "    new_mu, new_var = return_dict[\"encoder\"][\"mu\"], return_dict[\"encoder\"][\"var\"]\n",
    "    old_mu, old_var = return_dict[\"decoder\"][\"mu\"], return_dict[\"decoder\"][\"var\"]\n",
    "\n",
    "    loss_kl = gaussian_kl(z_pred, new_mu, new_var, old_mu, old_var)\n",
    "\n",
    "    loss_total = loss_pitch * self.weight_pitch + loss_velocity * self.weight_velocity + \\\n",
    "      loss_style * self.weight_style + loss_entropy * self.weight_entropy + \\\n",
    "      loss_kl * self.weight_sampling # + loss_instrument * self.weight_instrument\n",
    "\n",
    "    stats_dict = {'kl': loss_kl, 'entropy': loss_entropy, 'ce_style': loss_style,\n",
    "                  'ce_pitch': loss_pitch, #'ce_instrument': loss_instrument,\n",
    "                  'mse_velocity': loss_velocity, 'total': loss_total}\n",
    "    return stats_dict\n",
    "    \n",
    "  def _step(self, data, update=True):\n",
    "    # get _elbo, optimize\n",
    "\n",
    "    # data needs to be: pitch, instrument, velocity, style_label\n",
    "    # pitch [N, T, X], instrument [N, T, Y], velocity [N, T, 1] ?\n",
    "    # style label is just [N, Z]\n",
    "\n",
    "    pitch, instrument, velocity, style = \\\n",
    "      data[\"pitch\"], data[\"instrument\"], data[\"velocity\"], data[\"style\"]\n",
    "    stats_dict = self._elbo(pitch, instrument, velocity, style)\n",
    "\n",
    "    final_loss = stats_dict[\"total\"]\n",
    "    \n",
    "    if update:  \n",
    "      self.optimizer.zero_grad()\n",
    "      final_loss.backward()\n",
    "      self.optimizer.step() # can use clipping, etc\n",
    "\n",
    "    return stats_dict\n",
    "\n",
    "  def train(self, data_loader):\n",
    "    # iterate on data loader using step\n",
    "\n",
    "    # decay lr and temp appropriately\n",
    "    \n",
    "    all_stats_dict = defaultdict(list)\n",
    "\n",
    "    for epoch in range(self.num_epochs):\n",
    "      epoch_dict = defaultdict(list)\n",
    "\n",
    "      for batch in data_loader:\n",
    "        stats = self._step(batch)\n",
    "\n",
    "        for key in stats:            \n",
    "          epoch_dict[key].append(stats[key].item()) # should be scalar\n",
    "\n",
    "      # aggregate stats\n",
    "      for key in epoch_dict:\n",
    "        epoch_dict[key] = np.mean(epoch_dict[key])\n",
    "        all_stats_dict[key].append(epoch_dict[key])\n",
    "\n",
    "      # do all epoch based updates\n",
    "      if epoch % self.decay_epoch == 0:\n",
    "        self.learning_rate *= self.lr_decay\n",
    "        \n",
    "      if epoch % self.decay_temp_rate == 0:\n",
    "        self.gumbel_temp = max(self.gumbel_temp * self.decay_temp, self.min_temp)\n",
    "\n",
    "      # save and log\n",
    "      if epoch % self.save_epoch == 0:\n",
    "        torch.save(self.model.state_dict(), self.save_path + \"model_{}\".format(epoch))\n",
    "      \n",
    "      if epoch % self.log_epoch == 0:\n",
    "        with open(self.save_path + \"stats_{}\".format(epoch), 'w') as f:\n",
    "          json.dump(all_stats_dict, f)\n",
    "\n",
    "        for key in epoch_dict:\n",
    "          logging.info(key + \" : {}\".format(epoch_dict[key]))\n",
    "\n",
    "  def test(self, data_loader):\n",
    "    # iterate\n",
    "    epoch_dict = defaultdict(list)\n",
    "\n",
    "    for batch in data_loader:\n",
    "      stats = _step(batch, update=False)\n",
    "\n",
    "      for key in stats:\n",
    "        epoch_dict[key].append(stats[key].item) \n",
    "    \n",
    "    for key in epoch_dict:\n",
    "      epoch_dict[key] = np.mean(epoch_dict[key])\n",
    "    \n",
    "    return epoch_dict()\n",
    "    \n",
    "\n",
    "  def run(self, train_loader, test_loader):\n",
    "    # train, test then plot outputs?? save model somehow\n",
    "    train_results = self.train(train_loader)\n",
    "    test_results = self.test(test_loader)\n",
    "\n",
    "    # plot outputs or something?\n",
    "    # pass\n",
    "    return train_results, test_results\n",
    "\n",
    "  def transfer(self, data):\n",
    "    # use the style transfer function in GMVAE\n",
    "\n",
    "    # don't use data loader, just load data in directly\n",
    "    pitch, instrument, velocity, style = \\\n",
    "      data[\"pitch\"], data[\"instrument\"], data[\"velocity\"], data[\"style\"]\n",
    "    \n",
    "    style = style.expand(list(style_label.shape)[0], list(pitch.shape)[1], list(style_label.shape)[1])\n",
    "    x = torch.cat(pitch, instrument, velocity, dim=-1) \n",
    "    return_dict = self.model.style_transfer(x, style)\n",
    "    \n",
    "    x_pred = return_dict[\"decoder\"][\"x\"]\n",
    "    pitch_pred, instrument_pred, velocity_pred = \\\n",
    "      torch.split(x_pred, [self.pitch_size, self.instrument_size, self.velocity_size], dim=-1)\n",
    "\n",
    "    # renormalizing?\n",
    "    velocity_pred = (velocity_pred + 1)/2 # is this correct? output of RNN should be in [0, 1]\n",
    "    \n",
    "    return pitch_pred.numpy(), instrument_pred.numpy(), velocity_pred.numpy() # is this good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "1BXWlLGdFkx3"
   },
   "outputs": [],
   "source": [
    "class music(Dataset):\n",
    "    \"\"\"music\"\"\"\n",
    "    def __init__(self, pitch_data, instrument_data, velocity_data, style_data):\n",
    "        \"\"\"\n",
    "        # pitch [N, T, X], instrument [N, T, Y], velocity [N, T, 1] ?\n",
    "        # style label is just [N, Z]\n",
    "        \"\"\"\n",
    "        self.pitch_data = pitch_data\n",
    "        self.instrument_data = instrument_data\n",
    "        self.velocity_data = velocity_data\n",
    "        self.style_data = style_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.style_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = torch.tensor(self.pitch_data[idx], dtype=torch.float)\n",
    "        i = torch.tensor(self.instrument_data[idx], dtype=torch.float)\n",
    "        v = torch.tensor(self.velocity_data[idx], dtype=torch.float)\n",
    "        s = torch.tensor(self.style_data[idx], dtype=torch.int)\n",
    "            \n",
    "        f = lambda z: torch.nn.utils.rnn.pad_sequence(z, batch_first=True)\n",
    "        \n",
    "        sample = {\"pitch\": f(p), \"instrument\": f(i), \"velocity\": f(v), \"style\": s}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "O-mInos7mMhj"
   },
   "outputs": [],
   "source": [
    "# shared constants\n",
    "\n",
    "PITCH_DIM = 61\n",
    "INSTRUMENT_DIM = 1 # same as pitch pls?\n",
    "VELOCITY_DIM = 1 \n",
    "\n",
    "NUM_STYLES = 3\n",
    "LATENT_DIM = 64 # ??\n",
    "\n",
    "BATCH_SIZE = 128 # bigger if possible, but might kill GPU\n",
    "\n",
    "RNN_CELL = \"gru\"\n",
    "RNN_CELL_NUMBER = LATENT_DIM # this is a lot\n",
    "\n",
    "# all hyperparameters in here lol\n",
    "# sorry, hope this is easy to read\n",
    "encoder_dict = {\n",
    "    \"q_y_rnn\": {\"input_dim\": PITCH_DIM + INSTRUMENT_DIM + VELOCITY_DIM,\n",
    "                \"output_dim\": 3 * LATENT_DIM,\n",
    "                \"rnn_cell\": RNN_CELL},\n",
    "    \"q_y_linear\": {\"input_dim\": 3 * LATENT_DIM,\n",
    "                   \"output_dim\": LATENT_DIM,\n",
    "                   \"output_activation_fn\": \"relu\"},\n",
    "    \"q_y_gumbel\": {\"input_dim\": LATENT_DIM,\n",
    "                   \"output_dim\": NUM_STYLES},\n",
    "\n",
    "    \"q_z_rnn\": {\"input_dim\": PITCH_DIM + INSTRUMENT_DIM + VELOCITY_DIM,\n",
    "                \"output_dim\": 3 * LATENT_DIM,\n",
    "                \"rnn_cell\": RNN_CELL},\n",
    "    \"q_z_linear\": {\"input_dim\": 3 * LATENT_DIM + NUM_STYLES,\n",
    "                   \"output_dim\": LATENT_DIM,\n",
    "                   \"output_activation_fn\": \"relu\"},\n",
    "    \"q_z_gaussian\": {\"input_dim\": LATENT_DIM,\n",
    "                     \"output_dim\": LATENT_DIM},\n",
    "}\n",
    "\n",
    "decoder_dict = {\n",
    "    \"input_dim\": NUM_STYLES,\n",
    "    \"output_dim\": LATENT_DIM,\n",
    "\n",
    "    \"p_x_linear\": {\"input_dim\": LATENT_DIM,\n",
    "                   \"output_dim\": 3 * LATENT_DIM,\n",
    "                   \"output_activation_fn\": \"tanh\"}, # tanh better for rnn?\n",
    "    \"p_x_rnn\": {\"input_dim\": 3 * LATENT_DIM,\n",
    "                \"output_dim\": PITCH_DIM + INSTRUMENT_DIM + VELOCITY_DIM,\n",
    "                \"rnn_cell\": RNN_CELL},\n",
    "}\n",
    "\n",
    "argdict = {\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"decay_epoch\": 25,\n",
    "    \"lr_decay\": 5e-1,\n",
    "\n",
    "    # tune these\n",
    "    \"weight_style\": 1,\n",
    "    \"weight_entropy\": 0.5,\n",
    "    \"weight_sampling\": 1,\n",
    "\n",
    "    \"weight_pitch\": 1,\n",
    "    \"weight_velocity\": 1,\n",
    "    \"weight_instrument\": 1,\n",
    "\n",
    "    \"pitch_size\": PITCH_DIM, #idk,\n",
    "    \"instrument_size\": INSTRUMENT_DIM, # idk\n",
    "    \"velocity_size\": VELOCITY_DIM,\n",
    "\n",
    "    \"init_temp\": 1e-1,\n",
    "    \"decay_temp\": 1e-1,\n",
    "    \"min_temp\": 1e-5,\n",
    "    \"decay_temp_rate\": 25, # every N epochs\n",
    "\n",
    "    \"cuda\": False, # use GPU if possible\n",
    "\n",
    "    \"num_epochs\": 100, # other paper uses 400, that's nuts\n",
    "\n",
    "    \"save_epoch\": 5,\n",
    "    \"log_epoch\": 5,\n",
    "\n",
    "    \"save_path\": \"./output/\",\n",
    "    \"encoder\": encoder_dict,\n",
    "    \"decoder\": decoder_dict,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_midi import import_midi_from_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "b8iHkNpV1LFv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98_Degrees_-_I_Do_Cherish_You.mid\n",
      "Importing Pop song called 98_Degrees_-_I_Do_Cherish_You.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  180.705792\n",
      "Tempo:  85.00004250002125\n",
      "fs:  5.666669500001417\n",
      "Total ticks:  1024\n",
      "Max concurrent notes:  6\n",
      "Max concurrent notes:  2\n",
      "[6, 2]\n",
      "Silent tracks if no override:  2\n",
      "Override programs:  [3, 1]\n",
      "5ive_-_Keep_On_Moving.mid\n",
      "Importing Pop song called 5ive_-_Keep_On_Moving.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  198.82827205\n",
      "Tempo:  134.00005806669182\n",
      "fs:  8.933337204446122\n",
      "Total ticks:  1777\n",
      "Max concurrent notes:  8\n",
      "Max concurrent notes:  6\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  4\n",
      "Max concurrent notes:  3\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  4\n",
      "[8, 6, 5, 4, 3, 2, 5, 1, 1, 4]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "5ive_-_Until_The_Time_Is_Through.mid\n",
      "Importing Pop song called 5ive_-_Until_The_Time_Is_Through.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0.0\n",
      "Song end:  225.74988712500001\n",
      "Tempo:  102.0000510000255\n",
      "fs:  6.8000034000017\n",
      "Total ticks:  1536\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  3\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  4\n",
      "[5, 5, 5, 5, 5, 2, 2, 3, 2, 2, 2, 4]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "5ive_-_If_Ya_Gettin_Down.mid\n",
      "Importing Pop song called 5ive_-_If_Ya_Gettin_Down.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  193.63652499999998\n",
      "Tempo:  109.99990833340973\n",
      "fs:  7.333327222227316\n",
      "Total ticks:  1421\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  4\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  4\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  4\n",
      "[2, 4, 2, 4, 1, 2, 1, 1, 1, 1, 1, 2, 4]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "702_-_Where_My_Girls_At.mid\n",
      "Importing Pop song called 702_-_Where_My_Girls_At.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  187.78889398958333\n",
      "Tempo:  93.00004185001883\n",
      "fs:  6.200002790001254\n",
      "Total ticks:  1165\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "[5, 1, 1, 1]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1]\n",
      "Aaliyah_-_Are_You_That_Somebody.mid\n",
      "Importing Pop song called Aaliyah_-_Are_You_That_Somebody.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  265.25950459999996\n",
      "Tempo:  132.9999468000213\n",
      "fs:  8.86666312000142\n",
      "Total ticks:  2352\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "[1, 1, 1, 1, 1, 1, 2, 1, 2]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "5ive_-_Slam_Dunk_Da_Funk.mid\n",
      "Importing Pop song called 5ive_-_Slam_Dunk_Da_Funk.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  219.32028599999998\n",
      "Tempo:  103.0000480666891\n",
      "fs:  6.866669871112608\n",
      "Total ticks:  1507\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  6\n",
      "Max concurrent notes:  6\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  4\n",
      "[1, 1, 1, 2, 1, 2, 6, 6, 1, 1, 4]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "5ive_-_You_Got_The_Feelin.mid\n",
      "Importing Pop song called 5ive_-_You_Got_The_Feelin.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  210.215\n",
      "Tempo:  100.0\n",
      "fs:  6.666666666666667\n",
      "Total ticks:  1402\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  6\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  3\n",
      "[5, 5, 2, 2, 1, 2, 6, 2, 1, 3]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "98_Degrees_-_The_Hardest_Thing.mid\n",
      "Importing Pop song called 98_Degrees_-_The_Hardest_Thing.mid\n",
      "Time signature changes:  []\n",
      "Song start:  0\n",
      "Song end:  221.0\n",
      "Tempo:  120.0\n",
      "fs:  8.0\n",
      "Total ticks:  1768\n",
      "Max concurrent notes:  3\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "[3, 2, 1, 1, 1, 1]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1]\n",
      "5ive_-_Dont_Wanna_Let_You_Go.mid\n",
      "Importing Pop song called 5ive_-_Dont_Wanna_Let_You_Go.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  197.47563599999998\n",
      "Tempo:  103.0000480666891\n",
      "fs:  6.866669871112608\n",
      "Total ticks:  1356\n",
      "Max concurrent notes:  3\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  0\n",
      "[3, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 0]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Bagatella op33 n2.mid\n",
      "Importing Classic song called Bagatella op33 n2.mid\n",
      "Time signature changes:  [TimeSignature(numerator=3, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  202.08313125\n",
      "Tempo:  180.00018000018\n",
      "fs:  12.000012000012\n",
      "Total ticks:  2425\n",
      "Max concurrent notes:  3\n",
      "Max concurrent notes:  4\n",
      "[3, 4]\n",
      "Silent tracks if no override:  2\n",
      "Override programs:  [3, 1]\n",
      "Bagatella op33 n5.mid\n",
      "Importing Classic song called Bagatella op33 n5.mid\n",
      "Time signature changes:  [TimeSignature(numerator=3, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  143.08333333333331\n",
      "Tempo:  120.0\n",
      "fs:  8.0\n",
      "Total ticks:  1145\n",
      "Max concurrent notes:  4\n",
      "Max concurrent notes:  4\n",
      "[4, 4]\n",
      "Silent tracks if no override:  2\n",
      "Override programs:  [3, 1]\n",
      "Bagatella op33 n1.mid\n",
      "Importing Classic song called Bagatella op33 n1.mid\n",
      "Time signature changes:  [TimeSignature(numerator=6, denominator=8, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  204.80967741666666\n",
      "Tempo:  104.99992125005907\n",
      "fs:  6.999994750003938\n",
      "Total ticks:  1434\n",
      "Max concurrent notes:  3\n",
      "Max concurrent notes:  4\n",
      "[3, 4]\n",
      "Silent tracks if no override:  2\n",
      "Override programs:  [3, 1]\n",
      "Bagatella Fur Elise.mid\n",
      "Importing Classic song called Bagatella Fur Elise.mid\n",
      "Time signature changes:  [TimeSignature(numerator=3, denominator=4, time=0.0)]\n",
      "Song start:  58.640797716666654\n",
      "Song end:  131.09667836666665\n",
      "Tempo:  159.0002067002687\n",
      "fs:  10.600013780017914\n",
      "Total ticks:  1390\n",
      "Max concurrent notes:  6\n",
      "[6]\n",
      "Silent tracks if no override:  3\n",
      "Override programs:  [4]\n",
      "Bagatella op33 n4.mid\n",
      "Importing Classic song called Bagatella op33 n4.mid\n",
      "Time signature changes:  [TimeSignature(numerator=2, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  97.237998\n",
      "Tempo:  105.000105000105\n",
      "fs:  7.000007000007\n",
      "Total ticks:  681\n",
      "Max concurrent notes:  3\n",
      "Max concurrent notes:  2\n",
      "[3, 2]\n",
      "Silent tracks if no override:  2\n",
      "Override programs:  [3, 1]\n",
      "Bagatella op33 n3.mid\n",
      "Importing Classic song called Bagatella op33 n3.mid\n",
      "Time signature changes:  [TimeSignature(numerator=6, denominator=8, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  99.575658\n",
      "Tempo:  165.000165000165\n",
      "fs:  11.000011000011\n",
      "Total ticks:  1096\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  3\n",
      "[2, 3]\n",
      "Silent tracks if no override:  2\n",
      "Override programs:  [2, 2]\n",
      "Anh08Nb1 Gavotte 4 hands.mid\n",
      "Importing Classic song called Anh08Nb1 Gavotte 4 hands.mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0.0\n",
      "Song end:  93.735\n",
      "Tempo:  100.0\n",
      "fs:  6.666666666666667\n",
      "Total ticks:  625\n",
      "Max concurrent notes:  4\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "[4, 2, 2, 2]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1]\n",
      "Bagatella op33 n6.mid\n",
      "Importing Classic song called Bagatella op33 n6.mid\n",
      "Time signature changes:  [TimeSignature(numerator=2, denominator=4, time=0.0)]\n",
      "Song start:  0.0\n",
      "Song end:  129.3155955\n",
      "Tempo:  95.00014250021376\n",
      "fs:  6.333342833347584\n",
      "Total ticks:  820\n",
      "Max concurrent notes:  4\n",
      "Max concurrent notes:  4\n",
      "[4, 4]\n",
      "Silent tracks if no override:  2\n",
      "Override programs:  [3, 1]\n",
      "Anh06 Rondo.mid\n",
      "Importing Classic song called Anh06 Rondo.mid\n",
      "Time signature changes:  [TimeSignature(numerator=6, denominator=8, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  336.8752695\n",
      "Tempo:  143.99988480009216\n",
      "fs:  9.599992320006145\n",
      "Total ticks:  3234\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  4\n",
      "[5, 4]\n",
      "Silent tracks if no override:  2\n",
      "Override programs:  [3, 1]\n",
      "2_of_a_kind_jp.mid\n",
      "Importing Jazz song called 2_of_a_kind_jp.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  250.0\n",
      "Tempo:  120.0\n",
      "fs:  8.0\n",
      "Total ticks:  2000\n",
      "Max concurrent notes:  6\n",
      "Max concurrent notes:  4\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  4\n",
      "[6, 4, 2, 2, 2, 4]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1]\n",
      "a_foggy_day_r_gw.mid\n",
      "Importing Jazz song called a_foggy_day_r_gw.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  194.21011199999998\n",
      "Tempo:  152.00032426735845\n",
      "fs:  10.13335495115723\n",
      "Total ticks:  1968\n",
      "Max concurrent notes:  6\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  5\n",
      "[6, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 5]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "a_house_is_not_a_home_dm.mid\n",
      "Importing Jazz song called a_house_is_not_a_home_dm.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  353.95445106666665\n",
      "Tempo:  88.00002346667293\n",
      "fs:  5.866668231111529\n",
      "Total ticks:  2077\n",
      "Max concurrent notes:  7\n",
      "[7]\n",
      "Silent tracks if no override:  3\n",
      "Override programs:  [4]\n",
      "a_fine_romance_mw.mid\n",
      "Importing Jazz song called a_fine_romance_mw.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  198.0\n",
      "Tempo:  160.0\n",
      "fs:  10.666666666666666\n",
      "Total ticks:  2112\n",
      "Max concurrent notes:  7\n",
      "Max concurrent notes:  6\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  4\n",
      "[7, 6, 2, 2, 2, 2, 4]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1]\n",
      "a_night_in_tunisia_2_jc.mid\n",
      "Importing Jazz song called a_night_in_tunisia_2_jc.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  164.571264\n",
      "Tempo:  140.00014000014\n",
      "fs:  9.333342666676\n",
      "Total ticks:  1536\n",
      "Max concurrent notes:  6\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  4\n",
      "[6, 2, 2, 2, 2, 2, 4]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1]\n",
      "a_lovely_way_to_spend_an_evening-1943-Vs2-kar_jpp (1).mid\n",
      "Importing Jazz song called a_lovely_way_to_spend_an_evening-1943-Vs2-kar_jpp (1).mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  49.2\n",
      "Song end:  203.40000000000003\n",
      "Tempo:  100.0\n",
      "fs:  6.666666666666667\n",
      "Total ticks:  1357\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "[5, 1, 1, 1, 1]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1]\n",
      "a_lovely_way_to_spend_an_evening-1943-Vs2-kar_jpp.mid\n",
      "Importing Jazz song called a_lovely_way_to_spend_an_evening-1943-Vs2-kar_jpp.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  49.2\n",
      "Song end:  203.40000000000003\n",
      "Tempo:  100.0\n",
      "fs:  6.666666666666667\n",
      "Total ticks:  1357\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  1\n",
      "[5, 1, 1, 1, 1]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1]\n",
      "a_day_in_the_life_of_a_fool_jhall.mid\n",
      "Importing Jazz song called a_day_in_the_life_of_a_fool_jhall.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  130.0\n",
      "Tempo:  120.0\n",
      "fs:  8.0\n",
      "Total ticks:  1040\n",
      "Max concurrent notes:  8\n",
      "Max concurrent notes:  5\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  3\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  6\n",
      "[8, 5, 2, 3, 2, 6]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1]\n",
      "500_miles_high-Chick-Corea_ee.mid\n",
      "Importing Jazz song called 500_miles_high-Chick-Corea_ee.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  4.0\n",
      "Song end:  231.99583333333334\n",
      "Tempo:  120.0\n",
      "fs:  8.0\n",
      "Total ticks:  1856\n",
      "Max concurrent notes:  6\n",
      "Max concurrent notes:  4\n",
      "Max concurrent notes:  3\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  28\n",
      "[6, 4, 3, 2, 28]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1]\n",
      "a_cottage_for_sale_rs.mid\n",
      "Importing Jazz song called a_cottage_for_sale_rs.mid\n",
      "Time signature changes:  [TimeSignature(numerator=4, denominator=4, time=0.0)]\n",
      "Song start:  0\n",
      "Song end:  213.0\n",
      "Tempo:  80.0\n",
      "fs:  5.333333333333333\n",
      "Total ticks:  1136\n",
      "Max concurrent notes:  7\n",
      "Max concurrent notes:  4\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  1\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  2\n",
      "Max concurrent notes:  5\n",
      "[7, 4, 2, 1, 2, 2, 2, 2, 2, 5]\n",
      "Silent tracks if no override:  0\n",
      "Override programs:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "29\n",
      "{0: 9, 1: 10, 2: 10}\n"
     ]
    }
   ],
   "source": [
    "v, vt, _, _, _, _, i, it, _, _, \\\n",
    "    p, pt, c, ct, _, _ = import_midi_from_folder(\"./data/original/\") # test\n",
    "\n",
    "# the original paper has some weird processing tricks\n",
    "# we ignore those, i don't really understand them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do some preprocessing on the data\n",
    "labels = []\n",
    "for i in range(len(p)):\n",
    "    temp_labels = [c[i]] * p[i].shape[0]\n",
    "    labels.extend(temp_labels)\n",
    "    \n",
    "labels_test = []\n",
    "for i in range(len(pt)):\n",
    "    temp_labels = [ct[i]] * p[i].shape[0]\n",
    "    labels_test.extend(temp_labels)\n",
    "    \n",
    "# instruments are too difficult to parse\n",
    "# just leave it as a random matrix\n",
    "v = np.concatenate(v, axis=0)[:,:,np.newaxis]\n",
    "vt = np.concatenate(vt, axis=0)[:,:,np.newaxis]\n",
    "\n",
    "p = np.concatenate(p, axis=0)\n",
    "pt = np.concatenate(pt, axis=0)[:,:,np.newaxis]\n",
    "\n",
    "i = np.random.random(v.shape)\n",
    "it = np.random.random(vt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2506, 64, 61)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = music(p, i, v, labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "test_data = music(pt, it, vt, labels_test)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(argdict)\n",
    "model.run(train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
