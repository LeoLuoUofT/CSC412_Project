{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import pretty_midi\n",
    "import warnings\n",
    "import os\n",
    "import import_midi as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Genre                               TrackID\n0   Pop      5ive_-_Dont_Wanna_Let_You_Go.mid\n1   Pop          5ive_-_If_Ya_Gettin_Down.mid\n2   Pop             5ive_-_Keep_On_Moving.mid\n3   Pop          5ive_-_Slam_Dunk_Da_Funk.mid\n4   Pop  5ive_-_Until_The_Time_Is_Through.mid\n\n['Pop', 'Jazz', 'Classic']\n\n{'Pop': 0, 'Jazz': 1, 'Classic': 2}\n\n"
     ]
    }
   ],
   "source": [
    "def get_genres(path):\n",
    "    \"\"\"\n",
    "    This function reads the genre labels and puts it into a pandas DataFrame.\n",
    "    \n",
    "    @input path: The path to the genre label file.\n",
    "    @type path: String\n",
    "    \n",
    "    @return: A pandas dataframe containing the genres and midi IDs.\n",
    "    @rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    genres = []\n",
    "    with open(path) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            if line[0] != '#':\n",
    "                [x, y, *_] = line.strip().split(\"\\t\")\n",
    "                ids.append(x)\n",
    "                genres.append(y)\n",
    "            line = f.readline()\n",
    "    genre_df = pd.DataFrame(data={\"Genre\": genres, \"TrackID\": ids})\n",
    "    return genre_df\n",
    "\n",
    "# Get the Genre DataFrame\n",
    "genre_path = \"new_labels_full.cls\"\n",
    "#genre_path = \"new_labels_small.cls\"\n",
    "genre_df = get_genres(genre_path)\n",
    "\n",
    "# Create Genre List and Dictionary\n",
    "label_list = list(set(genre_df.Genre))\n",
    "label_dict = {lbl: label_list.index(lbl) for lbl in label_list}\n",
    "\n",
    "# Print to Visualize\n",
    "print(genre_df.head(), end=\"\\n\\n\")\n",
    "print(label_list, end=\"\\n\\n\")\n",
    "print(label_dict, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                   Path    Genre\n0  classifier/data_onefile/003706b_.mid  Classic\n1  classifier/data_onefile/003806b_.mid  Classic\n2  classifier/data_onefile/003907bv.mid  Classic\n3  classifier/data_onefile/003907b_.mid  Classic\n4  classifier/data_onefile/004003b_.mid  Classic\n"
     ]
    }
   ],
   "source": [
    "#This function is used when all the tracks are in one folder\n",
    "def get_matched_midi_single(midi_folder, genre_df):\n",
    "    \"\"\"\n",
    "    This function loads in midi file paths that are found in the given folder, puts this data into a\n",
    "    pandas DataFrame, then matches each entry with a genre described in get_genres.\n",
    "    \n",
    "    @input midi_folder: The path to the midi files.\n",
    "    @type midi_folder: String\n",
    "    @input genre_df: The genre label dataframe generated by get_genres.\n",
    "    @type genre_df: pandas.DataFrame\n",
    "    \n",
    "    @return: A dataframe of track id and path to a midi file with that track id.\n",
    "    @rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    track_ids, file_paths = [], []\n",
    "    for filename in os.listdir(midi_path):\n",
    "\n",
    "        #IMPORTANT:\n",
    "        track_id = filename\n",
    "        #YOU'LL NEED TO CHANGE THIS WHEN USING LARGE DATASET\n",
    "\n",
    "        file_path = midi_path + \"/\" + filename\n",
    "        track_ids.append(track_id)\n",
    "        file_paths.append(file_path)\n",
    "    all_midi_df = pd.DataFrame({\"TrackID\": track_ids, \"Path\": file_paths})\n",
    "    df = pd.merge(all_midi_df, genre_df, on='TrackID', how='inner')\n",
    "    return df.drop([\"TrackID\"], axis=1)\n",
    "\n",
    "# Obtain DataFrame with Matched Genres to File Paths\n",
    "midi_path = \"data_onefile\"\n",
    "#midi_path = \"replacement_data\"\n",
    "matched_midi_df_replace = get_matched_midi_single(midi_path, genre_df)\n",
    "\n",
    "# Print to Check Correctness\n",
    "print(matched_midi_df_replace.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\leois\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pretty_midi\\pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n",
      "[[ 0.11333419  1.91        0.125       0.125       2.        ]\n",
      " [-0.13428571  1.91        0.125       0.125       2.        ]\n",
      " [-0.03066667  1.91        0.125       0.125       2.        ]\n",
      " ...\n",
      " [ 0.05458534 -0.41        0.125       0.125       0.        ]\n",
      " [ 0.17007582 -0.35        0.125       0.125       0.        ]\n",
      " [ 0.15167655 -0.35        0.125       0.125       0.        ]]\n",
      "Wall time: 12min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def normalize_features(features):\n",
    "    \"\"\"\n",
    "    This function normalizes the features to the range [-1, 1]\n",
    "    \n",
    "    @input features: The array of features.\n",
    "    @type features: List of float\n",
    "    \n",
    "    @return: Normalized features.\n",
    "    @rtype: List of float\n",
    "    \"\"\"\n",
    "    tempo = (features[0] - 150) / 300\n",
    "    num_sig_changes = (features[1] - 2) / 10\n",
    "    resolution = (features[2] - 260) / 400\n",
    "    time_sig_1 = (features[3] - 3) / 8\n",
    "    time_sig_2 = (features[4] - 3) / 8\n",
    "    return [tempo, resolution, time_sig_1, time_sig_2]\n",
    "\n",
    "\n",
    "def get_features(path):\n",
    "    \"\"\"\n",
    "    This function extracts the features from a midi file when given its path.\n",
    "    \n",
    "    @input path: The path to the midi file.\n",
    "    @type path: String\n",
    "    \n",
    "    @return: The extracted features.\n",
    "    @rtype: List of float\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file = pretty_midi.PrettyMIDI(path)\n",
    "        \n",
    "        tempo = file.estimate_tempo()\n",
    "        num_sig_changes = len(file.time_signature_changes)\n",
    "        resolution = file.resolution\n",
    "        ts_changes = file.time_signature_changes\n",
    "        ts_1 = 4\n",
    "        ts_2 = 4\n",
    "        if len(ts_changes) > 0:\n",
    "            ts_1 = ts_changes[0].numerator\n",
    "            ts_2 = ts_changes[0].denominator\n",
    "        return normalize_features([tempo, num_sig_changes, resolution, ts_1, ts_2])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_midi_features(path_df):\n",
    "    \"\"\"\n",
    "    This function takes in the path DataFrame, then for each midi file, it extracts certain\n",
    "    features, maps the genre to a number and concatenates these to a large design matrix to return.\n",
    "    \n",
    "    @input path_df: A dataframe with paths to midi files, as well as their corresponding matched genre.\n",
    "    @type path_df: pandas.DataFrame\n",
    "    \n",
    "    @return: A matrix of features along with label.\n",
    "    @rtype: numpy.ndarray of float\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    for index, row in path_df.iterrows():\n",
    "        features = get_features(row.Path)\n",
    "        genre = label_dict[row.Genre]\n",
    "        if features is not None:\n",
    "            features.append(genre)\n",
    "            all_features.append(features)\n",
    "    return np.array(all_features)\n",
    "\n",
    "labeled_features = extract_midi_features(matched_midi_df_replace)\n",
    "print(labeled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.07333368 -0.41        0.125       0.125     ]\n [ 0.02840157 -0.53        0.125       0.125     ]\n [ 0.22155298 -0.17        0.          0.125     ]\n [-0.08095273 -0.35        0.125       0.125     ]\n [ 0.21095911  0.31        0.125       0.125     ]\n [ 0.15113349 -0.35        0.125       0.125     ]\n [ 0.23704356  0.55        0.125       0.125     ]\n [ 0.12666654 -0.35        0.125       0.125     ]\n [ 0.26896419 -0.17        0.125       0.125     ]\n [ 0.18022747 -0.35        0.125       0.125     ]]\n[1 0 2 2 0 1 0 0 2 1]\n[[0 1 0]\n [1 0 0]\n [0 0 1]\n [0 0 1]\n [1 0 0]\n [0 1 0]\n [1 0 0]\n [1 0 0]\n [0 0 1]\n [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle Entire Dataset to Make Random\n",
    "labeled_features = np.random.permutation(labeled_features)\n",
    "\n",
    "# Partition into 3 Sets\n",
    "num = len(labeled_features)\n",
    "num_training = int(num * 0.8)\n",
    "num_validation = int(num * 0.9)\n",
    "training_data = labeled_features[:num_training]\n",
    "validation_data = labeled_features[num_training:num_validation]\n",
    "test_data = labeled_features[num_validation:]\n",
    "\n",
    "# Separate Features from Labels\n",
    "num_cols = training_data.shape[1] - 1\n",
    "training_features = training_data[:, :num_cols]\n",
    "validation_features = validation_data[:, :num_cols]\n",
    "test_features = test_data[:, :num_cols]\n",
    "\n",
    "# Format Features for Multi-class Classification\n",
    "num_classes = len(label_list)\n",
    "training_labels = training_data[:, num_cols].astype(int)\n",
    "validation_labels = validation_data[:, num_cols].astype(int)\n",
    "test_labels = test_data[:, num_cols].astype(int)\n",
    "\n",
    "# Function for One-Hot Encoding\n",
    "def one_hot(labels):\n",
    "    \"\"\"\n",
    "    This function encodes the labels using one-hot encoding.\n",
    "    \n",
    "    @input num_classes: The number of genres/classes.\n",
    "    @type num_classes: int\n",
    "    @input labels: The genre labels to encode.\n",
    "    @type labels: numpy.ndarray of int\n",
    "    \n",
    "    @return: The one-hot encoding of the labels.\n",
    "    @rtype: numpy.ndarray of int\n",
    "    \"\"\"\n",
    "    return np.eye(num_classes)[labels].astype(int)\n",
    "\n",
    "# Print to Check Dimentions and to Visualize\n",
    "print(test_features[:10])\n",
    "print(test_labels[:10])\n",
    "print(one_hot(test_labels)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\leois\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\leois\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\leois\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\leois\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best Accuracy: 0.6466666666666666\n"
     ]
    }
   ],
   "source": [
    "def train_model(t_features, t_labels, v_features, v_labels):\n",
    "    \"\"\"\n",
    "    This function trains a neural network using a couple different configurations.\n",
    "    \n",
    "    @input t_features: The training features.\n",
    "    @type t_features: numpy.ndarray of float\n",
    "    @input t_labels: The training labels.\n",
    "    @type t_labels: numpy.ndarray of int\n",
    "    @input v_features: The validation features.\n",
    "    @type v_features: numpy.ndarray of float\n",
    "    @input v_labels: The validation labels.\n",
    "    @type v_labels: numpy.ndarray of int\n",
    "    \n",
    "    @return: The classifier that achieved the best validation accuracy.\n",
    "    @rtype: sklearn.neural_network.multilayer_perceptron.MLPClassifier\n",
    "    \"\"\"\n",
    "    # Neural Network and SVM Configurations\n",
    "    clf_1 = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(5,), random_state=1)\n",
    "    clf_2 = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(5, 5), random_state=1)\n",
    "    clf_3 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(10, 10), random_state=1)\n",
    "    clf_4 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 100), random_state=1)\n",
    "    clf_svm = SVC()\n",
    "    \n",
    "    # Keep Track of the Best Model\n",
    "    best_clf = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    # Test the Accuracies of the Models and Get Best\n",
    "    for clf in [clf_1, clf_2, clf_3, clf_4, clf_svm]:\n",
    "        t_labels_hot = one_hot(t_labels)\n",
    "        v_labels_hot = one_hot(v_labels)\n",
    "        if (type(clf) == SVC):\n",
    "            clf = clf.fit(t_features, t_labels)\n",
    "        else:\n",
    "            clf = clf.fit(t_features, t_labels_hot)\n",
    "        predictions = clf.predict(v_features)\n",
    "        count = 0\n",
    "        for i in range(len(v_labels)):\n",
    "            if (type(clf) != SVC):\n",
    "                if np.array_equal(v_labels_hot[i], predictions[i]):\n",
    "                    count += 1\n",
    "            else:\n",
    "                if v_labels[i] == predictions[i]:\n",
    "                    count += 1\n",
    "        accuracy = count / len(v_labels_hot)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_clf = clf\n",
    "\n",
    "    print(\"Best Accuracy:\", best_accuracy)\n",
    "    return best_clf\n",
    "\n",
    "classifier = train_model(training_features, training_labels, validation_features, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6966666666666667\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(clf, t_features, t_labels):\n",
    "    \"\"\"\n",
    "    This function takes a trained model as well as the test features and its\n",
    "    corresponding labels, and reports the accuracy of the model.\n",
    "    \n",
    "    @input clf: The trained classifier.\n",
    "    @type model: sklearn.neural_network.multilayer_perceptron.MLPClassifier\n",
    "    @input t_features: The features from the test set.\n",
    "    @type f_features: numpy.ndarray of float\n",
    "    @input t_labels: The labels of the test set features.\n",
    "    @type t_labels: numpy.ndarray of int\n",
    "    \n",
    "    @return: The accuracy.\n",
    "    @rtype: float\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    predictions = clf.predict(t_features)\n",
    "    t_labels_hot = one_hot(t_labels)\n",
    "    for i in range(len(t_features)):\n",
    "        if (type(clf) == SVC):\n",
    "            if t_labels[i] == predictions[i]:\n",
    "                count += 1\n",
    "        else:\n",
    "            if np.array_equal(t_labels_hot[i], predictions[i]):\n",
    "                count += 1\n",
    "    return count / len(t_features)\n",
    "\n",
    "# Print the Test Accuracy\n",
    "print(calculate_accuracy(classifier, test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classic\n"
     ]
    }
   ],
   "source": [
    "def make_prediction(clf, midi_path):\n",
    "    \"\"\"\n",
    "    This function uses the classifier to predict the genre of a midi file.\n",
    "    \n",
    "    @input clf: The trained classifier.\n",
    "    @type clf: sklearn.neural_network.multilayer_perceptron.MLPClassifier\n",
    "    @input midi_path: The path to the midi file that we are trying to classify.\n",
    "    @type midi_path: String\n",
    "    \n",
    "    @return: The predicted genre of the midi file.\n",
    "    @rtype: String\n",
    "    \"\"\"\n",
    "    features = get_features(midi_path)\n",
    "    #if the classifier doesn't know it\n",
    "    prediction_ind = clf.predict([features])\n",
    "   \n",
    "    prediction = label_list[prediction_ind[0]]\n",
    "    return prediction\n",
    "    \n",
    "# Make a Prediction\n",
    "test_midi_path =\"replacement_data/c1.mid\"\n",
    "print(make_prediction(classifier, test_midi_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_folder(clf, midi_path):\n",
    "    \"\"\"\n",
    "    This function uses the classifier to predict the genre of a midi folder.\n",
    "    \n",
    "    @input clf: The trained classifier.\n",
    "    @type clf: sklearn.neural_network.multilayer_perceptron.MLPClassifier\n",
    "    @input midi_path: The path to the midi folder that we are trying to classify.\n",
    "    @type midi_path: String\n",
    "    \n",
    "    @return: The predicted genre of the midi file.\n",
    "    @rtype: String\n",
    "    \"\"\"\n",
    "    #for printing to file\n",
    "    #sys.stdout = open(\"classifier_output.txt\", \"w\")\n",
    "    for filename in os.listdir(midi_path):\n",
    "        file_path_list = midi_path + \"/\" + filename\n",
    "        output = make_prediction(clf, file_path_list)\n",
    "        print(filename+ \":\" +output)\n",
    "    #sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c1.mid:Classic\n",
      "c2.mid:Pop\n",
      "c3.mid:Classic\n",
      "c4.mid:Classic\n",
      "c5.mid:Classic\n",
      "c6.mid:Classic\n",
      "c7.mid:Classic\n",
      "c8.mid:Classic\n",
      "c9.mid:Classic\n",
      "j1.mid:Pop\n",
      "j2.mid:Pop\n",
      "j3.mid:Pop\n",
      "j4.mid:Pop\n",
      "j5.mid:Pop\n",
      "j6.mid:Pop\n",
      "j7.mid:Pop\n",
      "j8.mid:Pop\n",
      "j9.mid:Pop\n",
      "p1.mid:Pop\n",
      "p2.mid:Pop\n",
      "p3.mid:Pop\n",
      "p4.mid:Pop\n",
      "p5.mid:Pop\n",
      "p6.mid:Pop\n",
      "p7.mid:Pop\n",
      "p8.mid:Pop\n",
      "p9.mid:Pop\n"
     ]
    }
   ],
   "source": [
    "classify_folder(classifier, \"replacement_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(genre, path):\n",
    "    #for printing to file\n",
    "    sys.stdout = open(\"classifier/new_labels_small.cls\", \"w\",encoding='utf-8')\n",
    "    for filename in os.listdir(path):\n",
    "        print(filename +'\\t'+genre)\n",
    "    sys.stdout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd02403beabee1a99ebcb07e22007fb0eca45002b864c2d4a925444ccb553c7e04f",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "2403beabee1a99ebcb07e22007fb0eca45002b864c2d4a925444ccb553c7e04f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}